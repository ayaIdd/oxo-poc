{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be90318c",
   "metadata": {},
   "source": [
    "# no api / blocked web scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75487660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fake-useragent\n",
      "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: selenium in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.38.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.32.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.14.0)\n",
      "Downloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
      "Installing collected packages: fake-useragent\n",
      "Successfully installed fake-useragent-2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~jango (C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~jango (C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~jango (C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install fake-useragent pandas beautifulsoup4 selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b98809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 22:06:17,642 - INFO - ‚úì Dossier de session: scraping_session_20251102_220617\n",
      "2025-11-02 22:06:17,644 - INFO - \n",
      "üéØ D√âBUT SCRAPING: Lyon\n",
      "2025-11-02 22:06:17,645 - INFO - \n",
      "üéØ D√âBUT SCRAPING ULTRA FURTIF - Lyon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üïµÔ∏è  SCRAPER OXO - VERSION ULTRA FURTIVE\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 22:06:19,043 - INFO - ‚úÖ Chrome ultra furtif configur√© pour TripAdvisor\n",
      "2025-11-02 22:06:19,044 - INFO - \n",
      "üìñ Page 1/1\n",
      "2025-11-02 22:06:19,045 - INFO - üß≠ Navigation vers: https://www.tripadvisor.fr/Restaurants-g187265-oa0-Lyon.html\n",
      "2025-11-02 22:06:44,826 - INFO - üìÑ Page sauvegard√©e: scraping_session_20251102_220617\\tripadvisor_Lyon_page1.html\n",
      "2025-11-02 22:06:47,863 - INFO - ‚úì M√©thode secours: 0 restaurants\n",
      "2025-11-02 22:06:47,864 - INFO - üîç Extraction de 0 √©l√©ments\n",
      "2025-11-02 22:06:47,865 - INFO - ‚úÖ Page 1: 0 restaurants\n",
      "2025-11-02 22:06:47,866 - INFO - üéØ Lyon termin√©: 0 restaurants\n",
      "2025-11-02 22:06:47,866 - WARNING - ‚ùå Aucun r√©sultat, essai source alternative...\n",
      "2025-11-02 22:06:47,867 - INFO - \n",
      "üîÑ UTILISATION SOURCE ALTERNATIVE POUR Lyon\n",
      "2025-11-02 22:06:47,868 - INFO - ‚úÖ Lyon: 0 restaurants\n",
      "2025-11-02 22:06:47,870 - WARNING - ‚ö†Ô∏è Aucun lead √† sauvegarder!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úÖ MISSION ACCOMPLIE - MODE FURTIF ACTIV√â\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 22:06:50,314 - INFO - ‚úì Navigateur ferm√©\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Scraper OXO - Version ULTRA FURTIVE\n",
    "Contournement sp√©cifique des d√©tections TripAdvisor\n",
    "\"\"\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import random\n",
    "import re\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class UltraStealthScraper:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.leads = []\n",
    "        self.driver = None\n",
    "        self.session_folder = self._create_session_folder()\n",
    "        \n",
    "    def _create_session_folder(self):\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        folder = Path(f'scraping_session_{timestamp}')\n",
    "        folder.mkdir(exist_ok=True)\n",
    "        logger.info(f\"‚úì Dossier de session: {folder}\")\n",
    "        return folder\n",
    "\n",
    "    def setup_ultra_stealth_chrome(self):\n",
    "        try:\n",
    "            chrome_options = Options()\n",
    "            \n",
    "            chrome_options.add_argument('--start-maximized')\n",
    "            chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "            chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\", \"enable-logging\"])\n",
    "            chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n",
    "            chrome_options.add_argument('--disable-webrtc')\n",
    "            chrome_options.add_argument('--disable-features=WebRtcHideLocalIpsWithMdns')\n",
    "            chrome_options.add_argument('--no-sandbox')\n",
    "            chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "            chrome_options.add_argument('--disable-gpu')\n",
    "            chrome_options.add_argument('--disable-software-rasterizer')\n",
    "            chrome_options.add_argument('--lang=fr-FR')\n",
    "            chrome_options.add_argument('--accept-lang=fr-FR,fr;q=0.9,en;q=0.8')\n",
    "            chrome_options.add_argument('--disable-web-security')\n",
    "            chrome_options.add_argument('--allow-running-insecure-content')\n",
    "            chrome_options.add_argument('--disable-background-timer-throttling')\n",
    "            chrome_options.add_argument('--disable-renderer-backgrounding')\n",
    "            chrome_options.add_argument('--disable-backgrounding-occluded-windows')\n",
    "            chrome_options.add_argument('--disable-ipc-flooding-protection')\n",
    "            chrome_options.add_argument('--disable-hang-monitor')\n",
    "            \n",
    "            prefs = {\n",
    "                \"profile.default_content_setting_values.notifications\": 2,\n",
    "                \"profile.default_content_setting_values.geolocation\": 2,\n",
    "                \"profile.managed_default_content_settings.images\": 1,\n",
    "                \"intl.accept_languages\": \"fr-FR,fr\",\n",
    "                \"credentials_enable_service\": False,\n",
    "                \"profile.password_manager_enabled\": False\n",
    "            }\n",
    "            chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "            \n",
    "            self.driver = webdriver.Chrome(options=chrome_options)\n",
    "            \n",
    "            self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {\n",
    "                'source': '''\n",
    "                    Object.defineProperty(navigator, 'webdriver', {\n",
    "                        get: () => undefined\n",
    "                    });\n",
    "                    \n",
    "                    Object.defineProperty(navigator, 'plugins', {\n",
    "                        get: () => [1, 2, 3, 4, 5]\n",
    "                    });\n",
    "                    \n",
    "                    Object.defineProperty(navigator, 'languages', {\n",
    "                        get: () => ['fr-FR', 'fr', 'en-US', 'en']\n",
    "                    });\n",
    "                    \n",
    "                    window.chrome = {\n",
    "                        runtime: {},\n",
    "                        loadTimes: function() {},\n",
    "                        csi: function() {},\n",
    "                        app: {}\n",
    "                    };\n",
    "                    \n",
    "                    Object.defineProperty(navigator, 'permissions', {\n",
    "                        get: () => ({\n",
    "                            query: function(parameters) {\n",
    "                                return Promise.resolve({state: 'granted'});\n",
    "                            }\n",
    "                        })\n",
    "                    });\n",
    "                    \n",
    "                    Object.defineProperty(Intl, 'DateTimeFormat', {\n",
    "                        get: () => function() {\n",
    "                            return {resolvedOptions: () => ({timeZone: 'Europe/Paris'})};\n",
    "                        }\n",
    "                    });\n",
    "                '''\n",
    "            })\n",
    "            \n",
    "            logger.info(\"‚úÖ Chrome ultra furtif configur√© pour TripAdvisor\")\n",
    "            return self.driver\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Erreur configuration Chrome: {e}\")\n",
    "            raise\n",
    "\n",
    "    def ultra_human_delay(self, min_sec=3, max_sec=8):\n",
    "        base_delay = random.uniform(min_sec, max_sec)\n",
    "        micro_pauses = random.randint(0, 3)\n",
    "        for _ in range(micro_pauses):\n",
    "            time.sleep(random.uniform(0.1, 0.5))\n",
    "        time.sleep(base_delay)\n",
    "\n",
    "    def human_like_mouse_movement(self):\n",
    "        try:\n",
    "            actions = ActionChains(self.driver)\n",
    "            for i in range(random.randint(2, 4)):\n",
    "                x = random.randint(-50, 50)\n",
    "                y = random.randint(-30, 30)\n",
    "                actions.move_by_offset(x, y)\n",
    "                actions.pause(random.uniform(0.1, 0.3))\n",
    "            \n",
    "            if random.random() > 0.7:\n",
    "                actions.click()\n",
    "            \n",
    "            actions.perform()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def human_like_scroll_behavior(self):\n",
    "        scroll_patterns = [\n",
    "            [300, 600, 900, 1200],\n",
    "            [400, 800, 500, 1000],\n",
    "            [800, 400, 1200, 600]\n",
    "        ]\n",
    "        \n",
    "        pattern = random.choice(scroll_patterns)\n",
    "        \n",
    "        for scroll_pos in pattern:\n",
    "            scroll_script = f\"\"\"\n",
    "                window.scrollTo({{\n",
    "                    top: {scroll_pos},\n",
    "                    behavior: 'smooth'\n",
    "                }});\n",
    "            \"\"\"\n",
    "            self.driver.execute_script(scroll_script)\n",
    "            pause_time = random.uniform(0.5, 2.0)\n",
    "            time.sleep(pause_time)\n",
    "            \n",
    "            if random.random() > 0.6:\n",
    "                self.human_like_mouse_movement()\n",
    "\n",
    "    def simulate_human_reading(self, element=None):\n",
    "        reading_time = random.uniform(2, 6)\n",
    "        \n",
    "        if element:\n",
    "            self.driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", element)\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < reading_time:\n",
    "            if random.random() > 0.8:\n",
    "                self.human_like_mouse_movement()\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    def navigate_like_human(self, url):\n",
    "        logger.info(f\"üß≠ Navigation vers: {url}\")\n",
    "        self.ultra_human_delay(2, 5)\n",
    "        self.driver.get(url)\n",
    "        time.sleep(random.uniform(3, 6))\n",
    "        self.human_like_scroll_behavior()\n",
    "        \n",
    "        if self.is_tripadvisor_blocked():\n",
    "            self.handle_tripadvisor_block()\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def is_tripadvisor_blocked(self):\n",
    "        page_text = self.driver.page_source.lower()\n",
    "        \n",
    "        block_indicators = [\n",
    "            'vous avez √©t√© bloqu√©',\n",
    "            'why this block',\n",
    "            'something about the behavior',\n",
    "            'surfez et cliquez √† une vitesse surhumaine',\n",
    "            'cloudflare',\n",
    "            'distil networks',\n",
    "            'access denied',\n",
    "            'bot detected'\n",
    "        ]\n",
    "        \n",
    "        return any(indicator in page_text for indicator in block_indicators)\n",
    "\n",
    "    def handle_tripadvisor_block(self):\n",
    "        logger.warning(\"üö® TRIPADVISOR A D√âTECT√â LE SCRAPING!\")\n",
    "        self.save_page_for_analysis('tripadvisor_blocked_page')\n",
    "        logger.info(\"üõ°Ô∏è  Application des contre-mesures...\")\n",
    "        \n",
    "        long_wait = random.uniform(120, 300)\n",
    "        logger.info(f\"‚è≥ Longue pause de {long_wait/60:.1f} minutes...\")\n",
    "        time.sleep(long_wait)\n",
    "        \n",
    "        self.driver.delete_all_cookies()\n",
    "        self.driver.execute_script(\"window.localStorage.clear();\")\n",
    "        self.driver.execute_script(\"window.sessionStorage.clear();\")\n",
    "        \n",
    "        diversion_urls = [\n",
    "            \"https://www.google.com\",\n",
    "            \"https://www.wikipedia.org\",\n",
    "            \"https://www.youtube.com\"\n",
    "        ]\n",
    "        self.driver.get(random.choice(diversion_urls))\n",
    "        time.sleep(random.uniform(10, 20))\n",
    "        \n",
    "        logger.info(\"üîÑ Reprise du scraping apr√®s contre-mesures...\")\n",
    "\n",
    "    def save_page_for_analysis(self, name: str):\n",
    "        if self.driver:\n",
    "            filepath = self.session_folder / f'{name}.html'\n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                f.write(self.driver.page_source)\n",
    "            logger.info(f\"üìÑ Page sauvegard√©e: {filepath}\")\n",
    "\n",
    "    def scrape_tripadvisor_ultra_stealth(self, ville: str = \"Paris\", nb_pages: int = 1):\n",
    "        logger.info(f\"\\nüéØ D√âBUT SCRAPING ULTRA FURTIF - {ville}\")\n",
    "        \n",
    "        if not self.driver:\n",
    "            self.setup_ultra_stealth_chrome()\n",
    "        \n",
    "        location_ids = {\n",
    "            'Paris': 'g187147',\n",
    "            'Lyon': 'g187265', \n",
    "            'Marseille': 'g187253',\n",
    "            'Toulouse': 'g187175',\n",
    "            'Nice': 'g187234'\n",
    "        }\n",
    "        \n",
    "        location_id = location_ids.get(ville, 'g187147')\n",
    "        results = []\n",
    "        \n",
    "        for page in range(nb_pages):\n",
    "            offset = page * 30\n",
    "            url = f\"https://www.tripadvisor.fr/Restaurants-{location_id}-oa{offset}-{ville}.html\"\n",
    "            \n",
    "            try:\n",
    "                logger.info(f\"\\nüìñ Page {page+1}/{nb_pages}\")\n",
    "                \n",
    "                if not self.navigate_like_human(url):\n",
    "                    logger.warning(\"‚ùå Blocage d√©tect√©, abandon de cette page\")\n",
    "                    continue\n",
    "                \n",
    "                self.simulate_human_reading()\n",
    "                \n",
    "                if page == 0:\n",
    "                    self.save_page_for_analysis(f'tripadvisor_{ville}_page1')\n",
    "                \n",
    "                page_leads = self.extract_restaurants_stealth(ville)\n",
    "                results.extend(page_leads)\n",
    "                \n",
    "                logger.info(f\"‚úÖ Page {page+1}: {len(page_leads)} restaurants\")\n",
    "                \n",
    "                if page < nb_pages - 1:\n",
    "                    pause_time = random.uniform(30, 90)\n",
    "                    logger.info(f\"‚è≥ Pause de {pause_time:.1f} secondes...\")\n",
    "                    time.sleep(pause_time)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"‚ùå Erreur page {page+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        logger.info(f\"üéØ {ville} termin√©: {len(results)} restaurants\")\n",
    "        return results\n",
    "\n",
    "    def extract_restaurants_stealth(self, ville: str):\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "        soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "        leads = []\n",
    "        restaurants = []\n",
    "        \n",
    "        selectors_to_try = [\n",
    "            'div[data-test*=\"restaurant\"]',\n",
    "            'div[data-test*=\"venue\"]', \n",
    "            'div.listing',\n",
    "            'div[class*=\"restaurant-card\"]',\n",
    "            'div[class*=\"listing\"]',\n",
    "            'a[href*=\"/Restaurant_Review\"]'\n",
    "        ]\n",
    "        \n",
    "        for selector in selectors_to_try:\n",
    "            elements = soup.select(selector)\n",
    "            if len(elements) > 5:\n",
    "                restaurants = elements\n",
    "                logger.info(f\"‚úì S√©lecteur: {selector} ({len(restaurants)} √©l√©ments)\")\n",
    "                break\n",
    "        \n",
    "        if len(restaurants) < 5:\n",
    "            all_links = soup.find_all('a', href=re.compile('/Restaurant_Review'))\n",
    "            restaurants = [link.find_parent('div') for link in all_links if link.find_parent('div')]\n",
    "            logger.info(f\"‚úì M√©thode secours: {len(restaurants)} restaurants\")\n",
    "        \n",
    "        logger.info(f\"üîç Extraction de {len(restaurants)} √©l√©ments\")\n",
    "        \n",
    "        for i, resto in enumerate(restaurants[:20]):\n",
    "            try:\n",
    "                if random.random() > 0.7:\n",
    "                    time.sleep(random.uniform(0.5, 1.5))\n",
    "                \n",
    "                lead = self.extract_single_restaurant_improved(resto, ville)\n",
    "                if lead and lead.get('raison_sociale'):\n",
    "                    leads.append(lead)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        return leads\n",
    "\n",
    "    def extract_single_restaurant_improved(self, resto, ville):\n",
    "        name = None\n",
    "        name_link = resto.find('a', href=re.compile('/Restaurant_Review'))\n",
    "        if name_link:\n",
    "            name = name_link.get_text(strip=True)\n",
    "            name = re.sub(r'^\\d+\\.\\s*', '', name)\n",
    "            name = re.sub(r'\\(\\d+.*?avis\\)', '', name)\n",
    "            name = re.sub(r'[^\\w\\s√Ä-√ø\\-&]', '', name).strip()\n",
    "        \n",
    "        if not name or len(name) < 2:\n",
    "            return None\n",
    "        \n",
    "        link = None\n",
    "        if name_link and name_link.get('href'):\n",
    "            href = name_link['href']\n",
    "            if '/Restaurant_Review' in href:\n",
    "                link = f\"https://www.tripadvisor.fr{href.split('?')[0]}\"\n",
    "        \n",
    "        rating = None\n",
    "        rating_selectors = [\n",
    "            'svg[aria-label*=\"sur 5\"]',\n",
    "            '[class*=\"rating\"]',\n",
    "            '[aria-label*=\"bubble\"]'\n",
    "        ]\n",
    "        \n",
    "        for selector in rating_selectors:\n",
    "            rating_elem = resto.select_one(selector)\n",
    "            if rating_elem:\n",
    "                aria_label = rating_elem.get('aria-label', '')\n",
    "                match = re.search(r'(\\d+[,.]?\\d*)\\s*sur\\s*5', aria_label)\n",
    "                if match:\n",
    "                    rating = float(match.group(1).replace(',', '.'))\n",
    "                    break\n",
    "        \n",
    "        nb_avis = None\n",
    "        review_text = resto.get_text()\n",
    "        avis_match = re.search(r'(\\d[\\d\\s]*)\\s*avis', review_text.replace('\\u202f', ''))\n",
    "        if avis_match:\n",
    "            try:\n",
    "                nb_avis = int(avis_match.group(1).replace(' ', ''))\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return {\n",
    "            'raison_sociale': name,\n",
    "            'ville': ville,\n",
    "            'note_tripadvisor': rating,\n",
    "            'nb_avis_tripadvisor': nb_avis,\n",
    "            'url_tripadvisor': link,\n",
    "            'source': 'tripadvisor',\n",
    "            'date_collecte': datetime.now().isoformat(),\n",
    "            'quality_score': (2 if rating else 0) + (1 if nb_avis else 0)\n",
    "        }\n",
    "\n",
    "    def alternative_data_source(self, ville: str):\n",
    "        logger.info(f\"\\nüîÑ UTILISATION SOURCE ALTERNATIVE POUR {ville}\")\n",
    "        return []\n",
    "\n",
    "    def save_results(self, leads, filename='restaurants_ultra_stealth'):\n",
    "        if not leads:\n",
    "            logger.warning(\"‚ö†Ô∏è Aucun lead √† sauvegarder!\")\n",
    "            return\n",
    "        \n",
    "        df = pd.DataFrame(leads)\n",
    "        csv_path = self.session_folder / f'{filename}.csv'\n",
    "        df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        logger.info(f\"\\nüíæ Fichier sauvegard√©: {csv_path}\")\n",
    "        logger.info(f\"üìä Total: {len(leads)} restaurants\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            logger.info(\"‚úì Navigateur ferm√©\")\n",
    "\n",
    "\n",
    "def main_ultra_stealth():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üïµÔ∏è  SCRAPER OXO - VERSION ULTRA FURTIVE\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    scraper = UltraStealthScraper()\n",
    "    \n",
    "    try:\n",
    "        villes = [\"Lyon\"]\n",
    "        nb_pages = 1\n",
    "        all_leads = []\n",
    "        \n",
    "        for ville in villes:\n",
    "            logger.info(f\"\\nüéØ D√âBUT SCRAPING: {ville}\")\n",
    "            leads = scraper.scrape_tripadvisor_ultra_stealth(ville, nb_pages)\n",
    "            \n",
    "            if len(leads) == 0:\n",
    "                logger.warning(\"‚ùå Aucun r√©sultat, essai source alternative...\")\n",
    "                leads = scraper.alternative_data_source(ville)\n",
    "            \n",
    "            all_leads.extend(leads)\n",
    "            logger.info(f\"‚úÖ {ville}: {len(leads)} restaurants\")\n",
    "        \n",
    "        scraper.save_results(all_leads)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚úÖ MISSION ACCOMPLIE - MODE FURTIF ACTIV√â\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erreur: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    finally:\n",
    "        scraper.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_ultra_stealth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a4eec3",
   "metadata": {},
   "source": [
    "## Anti-Blocking Strategy\n",
    "\n",
    "### Why Blocked\n",
    "- Bot signatures (webdriver property visible)\n",
    "- Automation flags exposed\n",
    "- Too fast, no human delays\n",
    "- No mouse/scroll behavior\n",
    "- Rate limiting triggers\n",
    "- WebRTC leaks\n",
    "\n",
    "### How I tried to Fixed It\n",
    "\n",
    "**Browser Masking**\n",
    "- Hide webdriver property\n",
    "- Spoof plugins/languages\n",
    "- Disable automation flags\n",
    "- Realistic User-Agent\n",
    "- Disable WebRTC\n",
    "\n",
    "**Human Simulation**\n",
    "- Random delays (3-8s)\n",
    "- Mouse movements\n",
    "- Scroll patterns\n",
    "- Reading pauses (2-6s)\n",
    "\n",
    "**Rate Limiting**\n",
    "- 30-90s between pages\n",
    "- Limit to 20 items/page\n",
    "- Start small (1 page)\n",
    "\n",
    "**Block Recovery**\n",
    "- Wait 2-5 minutes\n",
    "- Clear cookies/storage\n",
    "- Visit normal sites first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c8d04e",
   "metadata": {},
   "source": [
    "# dummy data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9d377",
   "metadata": {},
   "source": [
    "## Data Sources - What You Can Get\n",
    "\n",
    "### data.gouv.fr (Free)\n",
    "- SIRENE database\n",
    "- Company legal info, creation date\n",
    "- Activity code (APE/NAF)\n",
    "- Address\n",
    "- ‚ùå No director info, no financials\n",
    "\n",
    "### Pappers (Paid)\n",
    "- ‚úÖ Director name, age, function\n",
    "- CA, profits, employee count\n",
    "- SIREN/SIRET\n",
    "- Legal documents\n",
    "- Company history\n",
    "\n",
    "### INSEE (Free)\n",
    "- Official company registry\n",
    "- Legal info, activity codes\n",
    "- Creation/closure dates\n",
    "- ‚ùå No financials, no director contacts\n",
    "\n",
    "### societe.com (Freemium)\n",
    "- Director name, age, function\n",
    "- Financial data (CA, results)\n",
    "- Employee count\n",
    "- ‚ùå Limited free access\n",
    "\n",
    "### Google Maps (Free)\n",
    "- Restaurant name, address\n",
    "- Phone number, website\n",
    "- Opening hours, reviews\n",
    "- ‚ùå No director info, no financials\n",
    "\n",
    "### TripAdvisor (Free)\n",
    "- Restaurant name, ratings\n",
    "- Review count, cuisine type\n",
    "- Price range\n",
    "- ‚ùå No director info, no contacts\n",
    "\n",
    "### What's Hard to Get\n",
    "- ‚ùå Director email (very rare)\n",
    "- ‚ùå Director phone (almost never public)\n",
    "- ‚ùå LinkedIn profiles (manual or API)\n",
    "- ‚ùå Precise CA (often paid data)\n",
    "\n",
    "### Realistic Strategy\n",
    "1. **Company data**: data.gouv.fr or Pappers\n",
    "2. **Director name**: Pappers/societe.com\n",
    "3. **Contacts**: Manual + LinkedIn + website\n",
    "4. **Digital presence**: Google Maps + TripAdvisor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07509536",
   "metadata": {},
   "source": [
    "# Where to Get Each Required Data\n",
    "\n",
    "## Director Info\n",
    "\n",
    "| Data Needed | Best Source | Alternative |\n",
    "|-------------|-------------|-------------|\n",
    "| Nom, Pr√©nom | **Pappers** (paid) | societe.com |\n",
    "| Fonction | **Pappers** | societe.com |\n",
    "| √Çge | **Pappers** | societe.com |\n",
    "| Email pro | ‚ö†Ô∏è Manual (website, LinkedIn) | Hunter.io (paid) |\n",
    "| T√©l√©phone | ‚ö†Ô∏è Manual (website, Google) | 118712.fr |\n",
    "| LinkedIn | **LinkedIn scraping** | Manual search |\n",
    "\n",
    "## Company Info\n",
    "\n",
    "| Data Needed | Best Source | Alternative |\n",
    "|-------------|-------------|-------------|\n",
    "| Raison sociale | **data.gouv.fr** (free) | Any source |\n",
    "| SIREN | **data.gouv.fr** | Any source |\n",
    "| CA (300k-2M‚Ç¨) | **Pappers** (paid) | societe.com |\n",
    "| Effectif (5-20) | **Pappers** | data.gouv.fr |\n",
    "| Date cr√©ation | **data.gouv.fr** | Pappers |\n",
    "| Localisation | **data.gouv.fr** | Google Maps |\n",
    "\n",
    "## Digital Maturity Scoring\n",
    "\n",
    "| Data Needed | Source |\n",
    "|-------------|--------|\n",
    "| Online presence | **Google Maps** |\n",
    "| Reviews/ratings | **TripAdvisor** |\n",
    "| Website quality | Manual check |\n",
    "| Social media | Facebook/Instagram |\n",
    "\n",
    "## Recommended Pipeline\n",
    "\n",
    "1. **Start**: data.gouv.fr ‚Üí Get all restaurants (APE code 5610A/5610C)\n",
    "2. **Filter**: By location, creation date, size\n",
    "3. **Enrich**: Pappers ‚Üí Get CA, director name, age\n",
    "4. **Score**: Google Maps + TripAdvisor ‚Üí Digital maturity\n",
    "5. **Contact hunt**: Manual + LinkedIn + Hunter.io ‚Üí Email/phone\n",
    "6. **Validate**: Email verification tools\n",
    "\n",
    "## Reality Check\n",
    "- **Easy to get**: Company info, director name\n",
    "- **Hard to get**: Email, phone (80% manual work)\n",
    "- **Must pay**: Pappers for CA + director details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7b1f9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
